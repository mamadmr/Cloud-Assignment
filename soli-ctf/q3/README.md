
# Q3 â€“ CTF Container Management using Celery and Redis (Dockerized)

This project is part of a cloud computing assignment. It demonstrates how to use **Celery**, **Redis**, and **Docker SDK** to asynchronously start and stop CTF challenge containers using background workers.

---

## ğŸ“¦ Technologies Used

- ğŸ³ Docker, Docker Compose
- ğŸ Python 3.11
- âš™ï¸ Celery (asynchronous task queue)
- ğŸ§  Redis (message broker and result backend)
- ğŸ§° Docker SDK (to manage containers programmatically)

---

## ğŸ§± Project Structure

```

q3/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ celery\_setup.py        â† Celery configuration
â”œâ”€â”€ worker/
â”‚   â””â”€â”€ manager.py             â† Celery tasks (start/stop container)
â”œâ”€â”€ runner/
â”‚   â””â”€â”€ launcher.py            â† Script that sends tasks to worker
â”œâ”€â”€ Dockerfile.worker          â† Dockerfile for celery worker
â”œâ”€â”€ Dockerfile.runner          â† Dockerfile for test task runner
â”œâ”€â”€ docker-compose.yml         â† Compose file to orchestrate services
â”œâ”€â”€ requirements.txt           â† Python dependencies
â””â”€â”€ README.md

````

---

## ğŸš€ How to Run the Project

```bash
sudo docker compose up --build
````

The test launcher will:

1. Asynchronously start a Docker container using the worker
2. Then stop and remove it

---

## ğŸ“‚ Code Explanations

### ğŸ“Œ `Dockerfile.worker`

This file defines the container that runs the Celery worker:

```Dockerfile
FROM python:3.11-slim

WORKDIR /src
COPY . .

RUN pip install --no-cache-dir -r requirements.txt

CMD ["celery", "-A", "worker.manager", "worker", "--loglevel=info"]
```

**Explanation:**

* Uses a slim Python 3.11 base image
* Sets the working directory to `/src`
* Copies all source code into the container
* Installs Python dependencies
* Starts the Celery worker with the task module `worker.manager`

---

### ğŸ“Œ `Dockerfile.runner`

This container runs a one-time script to test the start/stop tasks:

```Dockerfile
FROM python:3.11-slim

WORKDIR /src
COPY . .

RUN pip install --no-cache-dir -r requirements.txt

CMD ["python", "runner/launcher.py"]
```

**Explanation:**

* Same base image and setup as the worker
* Instead of starting Celery, it runs the Python script `launcher.py` once to trigger tasks

---

### ğŸ“Œ `docker-compose.yml`

This file orchestrates all the services:

```yaml
services:
  redis:
    image: redis
    ports:
      - "6379:6379"
    restart: always

  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: celery_worker
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - redis
    restart: always

  test_launcher:
    build:
      context: .
      dockerfile: Dockerfile.runner
    container_name: test_launcher
    depends_on:
      - celery_worker
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    restart: "no"
```

**Explanation:**

* `redis`: the message broker for Celery
* `celery_worker`: runs background tasks to start/stop Docker containers
* `test_launcher`: sends a test task and exits after execution
* Docker socket is mounted so containers can control other containers

---

## ğŸ“Œ Task Behavior

### `start_container` task:

* Takes a team name, challenge name, and image
* Builds a dynamic container name
* Starts a new container using the given image

### `stop_container` task:

* Stops and removes the given container by name

---

## âœ… Sample Output

```bash
Started: {'status': 'running', 'name': 'teamX_juice_173218', 'short_id': 'dae351429c94'}
Stopped: {'status': 'removed', 'name': 'teamX_juice_173218'}
```

---

## ğŸ¥ Demo Suggestions

When recording your demo:

1. Run `docker compose up --build`
2. Show Redis and Celery connecting
3. Confirm the test container launches and completes
4. Show logs that the task succeeded
5. (Optional) Run `docker ps -a` to confirm containers were created and removed

---

